{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reports_from_csv():\n",
    "    df = pd.read_csv(\"All_Scraped.csv\")\n",
    "    report_list = df[\"Report\"].tolist()\n",
    "    return report_list\n",
    "\n",
    "previous_reports = read_reports_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "# options.add_argument('--headless=new')\n",
    "# options.add_argument('--ignore-certificate-errors')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "url = 'https://www.airdropbob.com/'\n",
    "\n",
    "driver.get(url)\n",
    "element = WebDriverWait(driver, 15).until(EC.visibility_of_element_located((By.ID, 'resultsRow')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(projects, new_scraped_writer, all_scraped_writer):\n",
    "    try:\n",
    "        projects.pop(4)\n",
    "        try:\n",
    "            projects.pop(9)\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    projects = [project.get_attribute('href') for project in projects]\n",
    "\n",
    "    for project in tqdm(projects, desc='Projects Scraping'):\n",
    "        if project not in previous_reports:\n",
    "            data = {}\n",
    "\n",
    "            response = requests.get(project)\n",
    "            soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "            try:\n",
    "                data['Name'] = soup.select_one('div.provider-name').text\n",
    "            except:\n",
    "                return None\n",
    "            try:\n",
    "                data['Website'] = soup.select_one('a.btn.btn-secondary.btn-block').get('href')\n",
    "            except:\n",
    "                data['Website'] = ''\n",
    "            data['Report'] = project\n",
    "            data['Telegram'] = ''\n",
    "            data['Twitter'] = ''\n",
    "            data['Discord'] = ''\n",
    "\n",
    "            new_scraped_writer.writerow(data)\n",
    "            all_scraped_writer.writerow(data)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projects Scraping: 100%|██████████| 13/13 [00:01<00:00, 10.32it/s]\n",
      "Projects Scraping: 100%|██████████| 13/13 [00:00<00:00, 3434.49it/s]\n",
      "Projects Scraping: 100%|██████████| 13/13 [00:00<00:00, 4287.64it/s]\n",
      "Projects Scraping: 100%|██████████| 2/2 [00:00<00:00, 2948.54it/s]\n"
     ]
    }
   ],
   "source": [
    "header = ['Name','Website','Telegram','Twitter','Discord','Report']\n",
    "with open(\"All_Scraped.csv\", mode='a', newline='', encoding='utf-8') as all_scraped_file, open(\"New_Scraped.csv\", mode='a', newline='', encoding='utf-8') as new_scraped_file:\n",
    "    new_scraped_writer = csv.DictWriter(new_scraped_file, fieldnames=header)\n",
    "    all_scraped_writer = csv.DictWriter(all_scraped_file, fieldnames=header)\n",
    "\n",
    "    next_button = driver.find_elements(By.CSS_SELECTOR, 'a.page-link')[-1]\n",
    "    while 'disabled' not in next_button.get_attribute('class'):\n",
    "        projects = driver.find_elements(By.CSS_SELECTOR, 'div.col-md-4 > a')\n",
    "        get_data(projects, new_scraped_writer, all_scraped_writer)\n",
    "\n",
    "        driver.execute_script(\"window.scrollBy(0, 1200);\")\n",
    "        sleep(1)\n",
    "\n",
    "        next_button = driver.find_elements(By.CSS_SELECTOR, 'a.page-link')[-1]\n",
    "        next_button.click()\n",
    "        sleep(5)\n",
    "\n",
    "        next_button = driver.find_elements(By.CSS_SELECTOR, 'a.page-link')[-1]\n",
    "    \n",
    "    projects = driver.find_elements(By.CSS_SELECTOR, 'div.col-md-4 > a')\n",
    "    get_data(projects[:10], new_scraped_writer, all_scraped_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Name','Website','Telegram','Twitter','Discord','Report']\n",
    "with open(\"All_Scraped.csv\", mode='a', newline='', encoding='utf-8') as all_scraped_file, open(\"New_Scraped.csv\", mode='a', newline='', encoding='utf-8') as new_scraped_file:\n",
    "    new_scraped_writer = csv.DictWriter(new_scraped_file, fieldnames=header)\n",
    "    all_scraped_writer = csv.DictWriter(all_scraped_file, fieldnames=header)\n",
    "    #     print('Writing to file...')\n",
    "    get_data(projects[:10], new_scraped_writer, all_scraped_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollBy(0, 1300);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.airdropbob.com/jok-ai-labs/airdrop-jok-ai-labs')\n",
    "soup = BeautifulSoup(r.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select_one('a.btn.btn-secondary.btn-block').get('href')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
